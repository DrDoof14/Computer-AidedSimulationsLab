{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b985d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#have to read the GW.pdf file which is stored in the Epidemic folder \n",
    "#then we can start coding this lab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16953a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't have to generate the distro ourselves and it's ok if we use libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd8b57d",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34f9e27",
   "metadata": {},
   "source": [
    "14 - Galton-Watson ProcessesWorkshop<br>\n",
    "Through simulation evaluate the extinction probability within  generation  i  (q_i) and the asymptotic extinction  probability  (q) for  a Galton-Watson process in which the number of children of an individual Y is  distributed as a Poisson(lambda) R.V.  with lambda=0.6, 0.8, 0.9 0.95, 0.99, 1.01, 1.05, 1.1, 1.3.\n",
    "\n",
    "Compare the results you  obtain with theoretical predictions, (by  finding numerically, when needed,  the solution of q= phi_Y(q)) \n",
    "\n",
    "In particular, you are requested to specify the stopping condition you have implemented in order to empirically \"detect\"   non-extinction condition.  Please try to provide a theoretical justification to such condition.\n",
    "\n",
    "For the case  \\lambda=0.8, obtain the empirical distribution (histogram) on the number of nodes in the tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08f5c667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ae9ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_values=[0.6, 0.8, 0.9,0.95, 0.99, 1.01, 1.05, 1.1, 1.3]\n",
    "np.random.seed(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1900c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these are the outputs for lambda equal to 0.6\n",
      "\n",
      "[0.5, 0.5, 0.3333333333333333, 0.5, 0.2, 0.3333333333333333, 0.2, 0.1111111111111111, 0.5, 0.16666666666666666, 0.09090909090909091, 0.0625, 1.0, 0.5, 0.3333333333333333, 0.2, 0.14285714285714285, 1.0, 0.3333333333333333, 0.5, 0.3333333333333333, 1.0]\n",
      "\n",
      "\n",
      "defaultdict(<class 'list'>, {0: [1], 1: [1], 2: [1], 3: [2], 4: [1, 2], 5: [2, 0, 2], 6: [1, 3, 1, 0], 7: [0, 1, 0, 1, 0], 8: [0, 2], 9: [1, 0], 10: [0]})\n",
      "\n",
      "\n",
      "the average q is equal to 0.40185048537321255 \n",
      "\n",
      "#############################################\n",
      "these are the outputs for lambda equal to 0.8\n",
      "\n",
      "[0.3333333333333333, 1.0, 1.0]\n",
      "\n",
      "\n",
      "defaultdict(<class 'list'>, {0: [1], 1: [2], 2: [0, 0]})\n",
      "\n",
      "\n",
      "the average q is equal to 0.7777777777777777 \n",
      "\n",
      "#############################################\n",
      "these are the outputs for lambda equal to 0.9\n",
      "\n",
      "[0.5, 1.0]\n",
      "\n",
      "\n",
      "defaultdict(<class 'list'>, {0: [1], 1: [1], 2: [0]})\n",
      "\n",
      "\n",
      "the average q is equal to 0.75 \n",
      "\n",
      "#############################################\n",
      "these are the outputs for lambda equal to 0.95\n",
      "\n",
      "[0.3333333333333333, 1.0, 1.0]\n",
      "\n",
      "\n",
      "defaultdict(<class 'list'>, {0: [1], 1: [2], 2: [0, 0]})\n",
      "\n",
      "\n",
      "the average q is equal to 0.7777777777777777 \n",
      "\n",
      "#############################################\n",
      "these are the outputs for lambda equal to 0.99\n",
      "\n",
      "[0.3333333333333333, 0.25, 0.14285714285714285, 0.3333333333333333, 0.125, 0.07692307692307693, 0.5, 0.3333333333333333, 0.2, 0.14285714285714285, 0.1111111111111111, 0.5, 0.2, 0.3333333333333333, 0.14285714285714285, 0.08333333333333333, 0.5, 0.3333333333333333, 0.2, 0.14285714285714285, 0.09090909090909091, 0.5, 0.3333333333333333, 0.25, 0.14285714285714285, 0.5, 0.16666666666666666, 0.07692307692307693, 0.3333333333333333, 0.2, 0.14285714285714285, 0.1, 0.07692307692307693, 0.0625, 0.047619047619047616, 0.3333333333333333, 0.2, 0.08333333333333333, 0.041666666666666664, 0.02631578947368421, 0.5, 0.3333333333333333, 0.2, 0.125, 0.09090909090909091, 0.06666666666666667, 0.05, 0.04, 0.03225806451612903, 0.02631578947368421, 0.02127659574468085, 0.017241379310344827, 0.014285714285714285, 0.011904761904761904, 1.0, 0.3333333333333333, 0.1111111111111111, 0.06666666666666667, 0.045454545454545456, 0.034482758620689655, 0.02702702702702703, 0.021739130434782608, 0.017543859649122806, 0.014492753623188406, 0.012195121951219513, 0.010309278350515464, 0.008849557522123894, 0.007633587786259542, 0.3333333333333333, 0.2, 0.125, 0.09090909090909091, 0.06666666666666667, 0.05263157894736842, 0.041666666666666664, 0.03333333333333333, 0.02631578947368421, 0.02127659574468085, 0.017857142857142856, 0.014925373134328358, 0.01282051282051282, 0.010638297872340425, 0.009009009009009009, 0.007692307692307693, 0.006711409395973154, 0.005952380952380952, 0.3333333333333333, 0.2, 0.125, 0.09090909090909091, 0.07142857142857142, 0.058823529411764705, 0.047619047619047616, 0.04, 0.034482758620689655, 0.027777777777777776, 0.023255813953488372, 0.018867924528301886, 0.015873015873015872, 0.013513513513513514, 0.011627906976744186, 0.01020408163265306, 0.00909090909090909, 0.00819672131147541, 0.007462686567164179, 1.0, 0.5, 0.25, 0.16666666666666666, 0.125, 0.1, 0.07692307692307693, 0.0625, 0.05263157894736842, 0.04, 0.03225806451612903, 0.02564102564102564, 1.0, 1.0, 1.0, 0.3333333333333333, 0.14285714285714285, 0.09090909090909091, 0.06666666666666667, 0.05263157894736842, 0.5, 0.2, 0.09090909090909091, 0.05555555555555555, 0.5, 0.25, 0.125, 0.08333333333333333, 0.05555555555555555, 0.04, 0.030303030303030304, 0.5, 0.3333333333333333, 0.16666666666666666, 0.1111111111111111, 0.07692307692307693, 0.058823529411764705, 0.043478260869565216, 0.034482758620689655, 1.0, 0.5, 0.3333333333333333, 0.25, 0.125, 0.07692307692307693, 0.5, 0.25, 0.16666666666666666, 0.09090909090909091, 0.058823529411764705, 1.0, 0.5, 0.25, 0.16666666666666666, 0.1, 0.0625, 0.3333333333333333, 0.2, 0.125, 0.09090909090909091, 0.058823529411764705, 0.038461538461538464, 0.5, 0.25, 0.14285714285714285, 0.08333333333333333, 0.058823529411764705, 0.038461538461538464, 0.02702702702702703, 0.02040816326530612, 0.015873015873015872, 1.0, 0.3333333333333333, 0.16666666666666666, 0.09090909090909091, 0.05555555555555555, 0.04, 0.03125, 0.025, 0.020833333333333332, 0.017543859649122806, 0.014925373134328358, 0.0125, 0.010526315789473684, 0.008928571428571428, 1.0, 0.5, 0.3333333333333333, 0.2, 0.14285714285714285, 0.1111111111111111, 0.08333333333333333, 0.0625, 0.045454545454545456, 0.03571428571428571, 0.029411764705882353, 0.024390243902439025, 0.020833333333333332, 0.017241379310344827, 0.014492753623188406, 0.012345679012345678, 0.010638297872340425, 0.5, 0.3333333333333333, 0.25, 0.16666666666666666, 0.1, 0.07142857142857142, 0.05555555555555555, 0.041666666666666664, 0.03333333333333333, 0.02702702702702703, 0.022727272727272728, 0.018867924528301886, 0.016129032258064516, 0.5, 0.3333333333333333, 0.16666666666666666, 0.1, 0.07142857142857142, 0.05555555555555555, 0.041666666666666664, 0.03333333333333333, 0.027777777777777776, 1.0, 0.3333333333333333, 0.16666666666666666, 0.1, 0.07142857142857142, 0.05, 0.5, 0.2, 0.125, 0.09090909090909091, 0.06666666666666667, 0.05263157894736842, 0.2, 0.09090909090909091, 0.05555555555555555, 0.038461538461538464, 1.0, 0.5, 0.25, 0.125, 0.08333333333333333, 0.05555555555555555, 0.041666666666666664, 0.03125, 0.5, 0.2, 0.125, 0.08333333333333333, 0.0625, 0.05, 0.041666666666666664, 0.034482758620689655, 0.25, 0.125, 0.07692307692307693, 0.05, 0.03571428571428571, 1.0, 0.3333333333333333, 0.16666666666666666, 0.09090909090909091, 0.0625, 0.047619047619047616, 0.03571428571428571, 0.027777777777777776, 0.3333333333333333, 0.16666666666666666, 0.1111111111111111, 0.07692307692307693, 0.05555555555555555, 0.043478260869565216, 0.03225806451612903, 0.02564102564102564, 1.0, 0.5, 0.2, 0.1111111111111111, 0.07142857142857142, 0.05, 0.038461538461538464, 0.030303030303030304, 1.0, 0.3333333333333333, 0.14285714285714285, 0.08333333333333333, 0.05263157894736842, 0.03571428571428571, 0.02702702702702703, 0.5, 0.3333333333333333, 0.2, 0.125, 0.06666666666666667, 0.043478260869565216, 0.030303030303030304, 0.023255813953488372, 0.01818181818181818, 1.0, 1.0, 1.0, 0.25, 0.1111111111111111, 0.06666666666666667, 0.04, 0.02631578947368421, 0.018867924528301886, 0.014492753623188406, 0.011627906976744186, 0.009708737864077669, 0.3333333333333333, 0.16666666666666666, 0.1, 0.06666666666666667, 0.045454545454545456, 0.034482758620689655, 0.027777777777777776, 0.022727272727272728, 0.018867924528301886, 0.015873015873015872, 0.0136986301369863, 0.011764705882352941, 0.01, 0.008695652173913044, 0.007633587786259542, 0.006711409395973154, 0.0058823529411764705, 0.5, 0.3333333333333333, 0.16666666666666666, 0.09090909090909091, 0.058823529411764705, 0.038461538461538464, 0.027777777777777776, 0.020833333333333332, 0.01639344262295082, 0.013513513513513514, 0.011363636363636364, 0.00980392156862745, 0.008620689655172414, 0.007633587786259542, 0.006711409395973154, 0.005952380952380952, 0.005291005291005291, 0.0047169811320754715, 0.00425531914893617, 0.0038461538461538464, 0.0035087719298245615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.2, 0.1111111111111111, 0.06666666666666667, 0.045454545454545456, 0.03225806451612903, 0.025, 0.02, 0.016666666666666666, 0.014084507042253521, 0.011904761904761904, 0.01020408163265306, 0.008695652173913044, 0.007518796992481203, 0.006622516556291391, 0.0058823529411764705, 0.005263157894736842, 0.0047169811320754715, 0.004273504273504274, 1.0, 0.5, 0.2, 0.1111111111111111, 0.0625, 0.043478260869565216, 0.03225806451612903, 0.024390243902439025, 0.0196078431372549, 0.015873015873015872, 0.013333333333333334, 0.011363636363636364, 0.009708737864077669, 0.008403361344537815, 0.007407407407407408, 0.006622516556291391, 0.005988023952095809, 0.005434782608695652, 0.004975124378109453, 0.0045662100456621, 0.004201680672268907, 0.0038910505836575876, 1.0, 0.5, 0.2, 0.125, 0.09090909090909091, 0.06666666666666667, 0.043478260869565216, 0.03125, 0.023809523809523808, 0.018867924528301886, 0.015625, 0.013333333333333334, 0.011627906976744186, 0.010309278350515464, 0.00909090909090909, 0.008064516129032258, 0.007246376811594203, 0.006578947368421052, 0.006024096385542169, 0.5, 0.3333333333333333, 0.2, 0.125, 0.09090909090909091, 0.07142857142857142, 0.058823529411764705, 0.045454545454545456, 0.03571428571428571, 0.02857142857142857, 0.022727272727272728, 0.018867924528301886, 0.015384615384615385, 0.012987012987012988, 0.3333333333333333, 0.2, 0.1111111111111111, 0.07692307692307693, 0.05555555555555555, 0.043478260869565216, 0.03333333333333333, 0.02702702702702703, 0.021739130434782608, 0.017857142857142856, 0.014925373134328358, 0.01282051282051282, 1.0, 1.0, 0.5, 0.3333333333333333, 0.25, 0.125, 0.07692307692307693, 0.05555555555555555, 0.041666666666666664, 0.03333333333333333, 0.027777777777777776, 0.25, 0.14285714285714285, 0.1, 0.06666666666666667, 0.05, 0.04, 0.5, 0.3333333333333333, 0.2, 0.125, 0.07142857142857142, 1.0, 0.25, 0.125, 0.07692307692307693, 0.05, 0.037037037037037035, 0.5, 0.25, 0.14285714285714285, 0.1, 0.07142857142857142, 0.05263157894736842, 0.038461538461538464, 0.3333333333333333, 0.16666666666666666, 0.09090909090909091, 0.058823529411764705, 0.043478260869565216, 0.034482758620689655, 0.027777777777777776, 0.3333333333333333, 0.2, 0.14285714285714285, 0.1, 0.07142857142857142, 0.05555555555555555, 0.043478260869565216, 0.3333333333333333, 0.2, 0.1111111111111111, 0.07142857142857142, 0.05, 1.0, 1.0, 0.5, 0.25, 0.125, 0.06666666666666667, 0.25, 0.125, 0.08333333333333333, 0.05263157894736842, 0.03571428571428571, 0.02702702702702703, 0.021739130434782608, 0.5, 0.16666666666666666, 0.09090909090909091, 0.0625, 0.047619047619047616, 0.038461538461538464, 0.03225806451612903, 0.027777777777777776, 0.023809523809523808, 0.5, 0.3333333333333333, 0.2, 0.125, 0.09090909090909091, 0.06666666666666667, 0.5, 0.25, 0.16666666666666666, 0.1, 0.25, 0.14285714285714285, 0.06666666666666667, 0.043478260869565216, 0.5, 0.3333333333333333, 0.25, 0.14285714285714285, 0.09090909090909091, 0.06666666666666667, 0.05, 0.037037037037037035, 0.2, 0.1111111111111111, 0.07692307692307693, 0.058823529411764705, 0.043478260869565216, 0.03333333333333333, 0.02631578947368421, 0.25, 0.125, 0.08333333333333333, 0.05555555555555555, 0.04, 0.030303030303030304, 0.024390243902439025, 0.0196078431372549, 1.0, 0.5, 0.25, 0.14285714285714285, 0.09090909090909091, 0.058823529411764705, 0.043478260869565216, 0.03225806451612903, 0.02564102564102564, 0.020833333333333332, 0.5, 0.3333333333333333, 0.25, 0.2, 0.16666666666666666, 0.14285714285714285, 0.1111111111111111, 0.09090909090909091, 0.0625, 0.3333333333333333, 0.2, 0.1, 0.06666666666666667, 0.047619047619047616, 0.3333333333333333, 0.2, 0.1, 0.058823529411764705, 0.04, 0.02857142857142857, 0.5, 0.3333333333333333, 0.2, 0.125, 0.08333333333333333, 0.058823529411764705, 0.043478260869565216, 0.034482758620689655, 0.02857142857142857, 0.023809523809523808, 0.3333333333333333, 0.2, 0.14285714285714285, 0.1, 0.07142857142857142, 0.05263157894736842, 0.038461538461538464, 1.0, 0.5, 0.25, 0.14285714285714285, 0.08333333333333333, 0.043478260869565216, 0.029411764705882353, 0.5, 0.3333333333333333, 0.2, 0.14285714285714285, 0.1, 0.06666666666666667, 0.05, 0.04, 0.03333333333333333, 0.027777777777777776, 0.023809523809523808, 0.5, 0.2, 0.1111111111111111, 0.07692307692307693, 0.058823529411764705, 0.04, 0.3333333333333333, 0.14285714285714285, 0.08333333333333333, 0.05555555555555555, 0.041666666666666664, 0.03225806451612903, 0.023809523809523808, 0.01818181818181818, 0.3333333333333333, 0.1, 0.05555555555555555, 0.037037037037037035, 0.027777777777777776, 0.022222222222222223, 0.017857142857142856, 0.014705882352941176, 0.0125, 0.010869565217391304, 0.009523809523809525, 0.00847457627118644, 0.007575757575757576, 1.0, 1.0, 0.5, 0.25, 0.14285714285714285, 0.1, 0.07692307692307693, 0.05555555555555555, 0.041666666666666664, 0.03225806451612903, 0.02631578947368421, 0.022222222222222223, 0.018867924528301886, 0.01639344262295082, 0.5, 0.2, 0.1111111111111111, 0.06666666666666667, 0.045454545454545456, 0.03333333333333333, 0.02631578947368421, 0.02127659574468085, 0.3333333333333333, 0.2, 0.125, 0.09090909090909091, 0.07142857142857142, 0.05555555555555555, 0.043478260869565216, 0.03571428571428571, 0.02857142857142857, 0.5, 0.25, 0.1111111111111111, 0.06666666666666667, 0.047619047619047616, 0.037037037037037035, 0.029411764705882353, 0.3333333333333333, 0.14285714285714285, 0.07142857142857142, 0.045454545454545456, 0.03225806451612903, 0.025, 0.02, 0.5, 0.2, 0.125, 0.09090909090909091, 0.07142857142857142, 0.058823529411764705, 0.047619047619047616, 0.037037037037037035, 0.02857142857142857, 0.023255813953488372, 0.3333333333333333, 0.16666666666666666, 0.1, 0.05555555555555555, 0.037037037037037035, 0.02702702702702703, 0.02127659574468085, 0.017241379310344827, 1.0, 0.5, 0.25, 0.125, 0.07692307692307693, 0.05555555555555555, 0.041666666666666664, 0.03333333333333333, 0.02631578947368421, 0.02127659574468085, 0.017241379310344827, 0.5, 0.3333333333333333, 0.16666666666666666, 0.1, 0.07142857142857142, 0.05263157894736842, 0.041666666666666664, 0.03225806451612903, 0.02631578947368421, 0.021739130434782608, 0.01818181818181818, 0.5, 0.2, 0.125, 0.07692307692307693, 0.05555555555555555, 0.04, 0.03125, 0.02564102564102564, 0.021739130434782608, 0.25, 0.125, 0.08333333333333333, 0.0625, 0.05, 0.041666666666666664, 0.034482758620689655, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "\n",
      "defaultdict(<class 'list'>, {0: [1], 1: [2], 2: [3, 0], 3: [2, 3, 0], 4: [1, 0, 1, 0, 0], 5: [1, 2], 6: [2, 2, 1], 7: [1, 0, 1, 0, 2], 8: [1, 0, 0, 2], 9: [1, 3, 3], 10: [2, 0, 0, 1, 0, 0, 2], 11: [2, 0, 5, 5, 2], 12: [1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 2, 2, 1, 2], 13: [0, 2, 4, 0, 1, 0, 1, 1, 2, 1, 1, 2, 1, 2], 14: [2, 0, 1, 0, 1, 0, 1, 1, 2, 1, 0, 2, 0, 5, 1, 2, 0, 0], 15: [2, 0, 1, 0, 0, 0, 1, 0, 0, 3, 0, 3, 0, 1, 1, 0, 0, 0, 0], 16: [0, 1, 1, 0, 0, 0, 1, 0, 0, 3, 0, 2], 17: [0, 0, 0, 2, 2, 0, 0, 0], 18: [1, 2, 3, 1], 19: [1, 1, 2, 0, 2, 1, 1], 20: [1, 0, 2, 0, 1, 0, 2, 0], 21: [0, 1, 0, 0, 3, 1], 22: [1, 1, 0, 3, 1], 23: [0, 1, 1, 0, 2, 2], 24: [2, 0, 1, 0, 3, 3], 25: [1, 1, 1, 2, 0, 4, 2, 1, 2], 26: [0, 2, 1, 2, 2, 0, 0, 1, 0, 1, 1, 3, 2, 2], 27: [0, 1, 0, 1, 0, 0, 1, 1, 2, 0, 0, 1, 0, 3, 1, 1, 1], 28: [1, 0, 0, 1, 2, 0, 0, 2, 0, 1, 0, 2, 0], 29: [1, 0, 2, 1, 0, 0, 2, 0, 0], 30: [0, 2, 1, 1, 0, 2], 31: [1, 2, 0, 0, 1, 0], 32: [4, 2, 1, 1], 33: [0, 1, 1, 2, 0, 2, 0, 2], 34: [1, 2, 0, 1, 0, 0, 0, 1], 35: [3, 1, 1, 2, 1], 36: [0, 2, 1, 2, 0, 0, 2, 1], 37: [2, 1, 0, 1, 1, 0, 3, 0], 38: [0, 1, 2, 1, 1, 1, 0, 1], 39: [0, 2, 2, 1, 2, 2, 0], 40: [1, 0, 1, 1, 4, 1, 2, 0, 2], 41: [0, 0, 0, 3, 2, 1, 4, 3, 2, 1, 1, 0], 42: [2, 1, 1, 1, 2, 0, 0, 1, 1, 1, 0, 2, 3, 0, 1, 2, 3], 43: [1, 0, 2, 2, 1, 3, 1, 2, 1, 0, 1, 0, 0, 1, 3, 1, 2, 2, 0, 2, 0], 44: [0, 0, 0, 0, 0, 0, 1, 2, 1, 2, 1, 2, 0, 1, 0, 1, 2, 1, 3, 1, 0, 1, 1, 2, 0], 45: [0, 1, 2, 1, 3, 0, 1, 2, 0, 2, 0, 1, 2, 1, 0, 0, 0, 1, 0, 1, 1, 0], 46: [0, 1, 2, 0, 0, 1, 4, 1, 1, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0], 47: [1, 0, 1, 1, 0, 0, 0, 2, 1, 1, 2, 0, 3, 0], 48: [2, 0, 2, 0, 1, 0, 2, 0, 2, 1, 1, 0], 49: [0, 0, 1, 0, 0, 3, 1, 0, 1, 0, 0], 50: [3, 0, 0, 2, 0, 0], 51: [1, 0, 1, 1, 3], 52: [0, 3, 1, 1, 2, 0], 53: [1, 1, 1, 0, 1, 1, 2], 54: [2, 1, 2, 1, 0, 0, 1], 55: [2, 0, 0, 1, 1, 0, 1], 56: [2, 0, 2, 1, 1], 57: [0, 0, 1, 1, 2, 3], 58: [3, 1, 0, 3, 2, 0, 0], 59: [1, 3, 1, 0, 0, 0, 0, 0, 1], 60: [1, 0, 1, 1, 0, 1], 61: [1, 1, 0, 2], 62: [3, 0, 5, 0], 63: [1, 0, 0, 2, 1, 0, 1, 2], 64: [4, 0, 0, 0, 2, 1, 1], 65: [3, 1, 0, 2, 1, 1, 0, 2], 66: [0, 1, 1, 1, 1, 2, 0, 2, 0, 1], 67: [1, 0, 0, 0, 0, 0, 1, 0, 3], 68: [2, 0, 3, 0, 1], 69: [2, 0, 3, 2, 1, 2], 70: [1, 0, 1, 1, 1, 1, 1, 0, 0, 1], 71: [2, 0, 0, 1, 1, 1, 2], 72: [0, 1, 1, 1, 2, 6, 0], 73: [1, 0, 1, 0, 1, 2, 0, 0, 0, 1, 0], 74: [1, 2, 1, 0, 0, 4], 75: [2, 2, 1, 1, 0, 1, 4, 2], 76: [2, 5, 1, 1, 0, 0, 2, 1, 0, 0, 1, 0, 1], 77: [0, 0, 1, 1, 1, 0, 0, 2, 1, 1, 0, 0, 1, 0], 78: [1, 2, 1, 2, 1, 1, 0, 1], 79: [2, 0, 1, 0, 0, 1, 1, 0, 2], 80: [1, 1, 3, 1, 0, 0, 1], 81: [2, 2, 3, 1, 1, 0, 1], 82: [1, 2, 0, 0, 0, 0, 1, 2, 2, 0], 83: [2, 1, 1, 4, 1, 1, 0, 1], 84: [0, 1, 1, 2, 1, 0, 1, 0, 2, 1, 2], 85: [1, 0, 2, 1, 0, 1, 0, 2, 0, 1, 1], 86: [1, 2, 0, 2, 0, 2, 0, 0, 0], 87: [3, 1, 0, 0, 0, 0, 1], 88: [0, 0, 0, 0, 0]})\n",
      "\n",
      "\n",
      "the average q is equal to 0.1660604423171113 \n",
      "\n",
      "#############################################\n",
      "these are the outputs for lambda equal to 1.01\n",
      "\n",
      "[0.3333333333333333, 0.5, 0.25, 0.5, 0.25, 1.0, 0.25, 0.5, 0.25, 0.14285714285714285, 0.3333333333333333, 0.2, 0.125, 0.3333333333333333, 0.2, 0.14285714285714285, 0.5, 0.3333333333333333, 1.0]\n",
      "\n",
      "\n",
      "defaultdict(<class 'list'>, {0: [1], 1: [2], 2: [1, 1], 3: [1, 1], 4: [0, 3], 5: [1, 1, 1], 6: [2, 0, 1], 7: [2, 0, 0], 8: [1, 0], 9: [0]})\n",
      "\n",
      "\n",
      "the average q is equal to 0.37600250626566417 \n",
      "\n",
      "#############################################\n",
      "these are the outputs for lambda equal to 1.05\n",
      "\n",
      "[1.0]\n",
      "\n",
      "\n",
      "defaultdict(<class 'list'>, {0: [1], 1: [0]})\n",
      "\n",
      "\n",
      "the average q is equal to 1.0 \n",
      "\n",
      "#############################################\n",
      "these are the outputs for lambda equal to 1.1\n",
      "\n",
      "[1.0]\n",
      "\n",
      "\n",
      "defaultdict(<class 'list'>, {0: [1], 1: [0]})\n",
      "\n",
      "\n",
      "the average q is equal to 1.0 \n",
      "\n",
      "#############################################\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m         freq[j]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfreq\u001b[49m:\n\u001b[1;32m     20\u001b[0m         r \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m j \u001b[38;5;241m*\u001b[39m freq[j]\n\u001b[1;32m     21\u001b[0m q\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mr))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lam in lambda_values:\n",
    "    generation_dict=defaultdict(list)\n",
    "    generation = 0\n",
    "    q=[]\n",
    "    generation_dict[generation].append(1) # first person\n",
    "    while sum(generation_dict[generation])!=0:\n",
    "        temp=generation+1\n",
    "        for _ in range(sum(generation_dict[generation])):\n",
    "            if generation== 0:\n",
    "                m = 1/1+sum(generation_dict[generation])\n",
    "            generation_dict[temp].append(np.random.poisson(lam))\n",
    "            freq={}\n",
    "            r=0\n",
    "            for j in generation_dict[temp]:\n",
    "                if j in freq:\n",
    "                    freq[j]+=1\n",
    "                else:\n",
    "                    freq[j]=1\n",
    "                for j in freq:\n",
    "                    r += j * freq[j]\n",
    "            q.append(1/(1+r))\n",
    "        generation= generation+1\n",
    "    \n",
    "    print(f'these are the outputs for lambda equal to {lam}\\n')\n",
    "    print(q)\n",
    "    print('\\n')\n",
    "    print(generation_dict)\n",
    "    print('\\n')\n",
    "    print(f'the average q is equal to {sum(q)/len(q)} \\n')\n",
    "    print('#############################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbedea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeps on going for lambda equal to 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a5b87ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reproduction probability for generation= m ** i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ff56207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extinction prob = 1/1+ (frequency * number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81e0655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how should we compute qi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5178235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extinction probability is increasing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f4ac7",
   "metadata": {},
   "source": [
    "lambda is equal to m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e157b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295c6603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
